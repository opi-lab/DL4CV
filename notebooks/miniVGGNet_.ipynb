{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbiBEkmz+SPO6FOxyxv4ig",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/opi-lab/DL4CV/blob/main/notebooks/miniVGGNet_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MiniVGGNet\n",
        "\n",
        "Andrés Marrugo, 2022\n",
        "\n",
        "Here we will implement MiniVGGNet (a shallow version of VGGNet). VGGNet was ﬁrst introduced by Simonyan and Zisserman in their 2014 paper, Very Deep Learning Convolutional Neural Networks for Large-Scale Image Recognition.\n",
        "The primary contribution of their work was demonstrating that an architecture with very small (3×3) ﬁlters can be trained to increasingly higher depths (16-19 layers) and obtain state-of-the-art classiﬁcation on the challenging ImageNet classiﬁcation challenge.\n",
        "\n",
        "Follow the code from the Deep Learning for Computer vision book by Adrian Rosenbrock, chapter 15.\n",
        "\n",
        "We will train MiniVGGNet with the CIFAR-10 dataset:\n",
        "\n",
        "- Load the CIFAR-10 dataset from disk.\n",
        "- Instantiate the MiniVGGNet architecture.\n",
        "- Train MiniVGGNet using the training data.\n",
        "- Evaluate network performance with the testing data."
      ],
      "metadata": {
        "id": "XHZVJkB-znKK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The description of MiniVGGNet is given in the following Table. We can now implement the network architecture using Keras.\n",
        "\n",
        "| Layer Type \t| Output Size \t| Filter Size / Stride \t|\n",
        "|---\t|---\t|---\t|\n",
        "| INPUT IMAGE \t| 32×32×3 \t|  \t|\n",
        "| CONV \t| 32×32×32 \t| 3×3,K = 32 \t|\n",
        "| ACT \t| 32×32×32 \t|  \t|\n",
        "| BN \t| 32×32×32 \t|  \t|\n",
        "| CONV \t| 32×32×32 \t| 3×3,K = 32 \t|\n",
        "| ACT \t| 32×32×32 \t|  \t|\n",
        "| BN \t| 32×32×32 \t|  \t|\n",
        "| POOL \t| 16×16×32 \t| 2×2 \t|\n",
        "| DROPOUT \t| 16×16×32 \t|  \t|\n",
        "| CONV \t| 16×16×64 \t| 3×3,K = 64 \t|\n",
        "| ACT \t| 16×16×64 \t|  \t|\n",
        "| BN \t| 16×16×64 \t|  \t|\n",
        "| CONV \t| 16×16×64 \t| 3×3,K = 64 \t|\n",
        "| ACT \t| 16×16×64 \t|  \t|\n",
        "| BN \t| 16×16×64 \t|  \t|\n",
        "| POOL \t| 8×8×64 \t| 2×2 \t|\n",
        "| DROPOUT \t| 8×8×64 \t|  \t|\n",
        "| FC \t| 512 \t|  \t|\n",
        "| ACT \t| 512 \t|  \t|\n",
        "| BN \t| 512 \t|  \t|\n",
        "| DROPOUT \t| 512 \t|  \t|\n",
        "| FC \t| 10 \t|  \t|\n",
        "| SOFTMAX \t| 10 \t|  \t|"
      ],
      "metadata": {
        "id": "i2Sy3SeU0gB9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Follow the instructions in the book and create a `minivggnet.py` file to implement VGGNet."
      ],
      "metadata": {
        "id": "w-96GilU6evK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Downgrade to tensorflow 2.7.0\n",
        "# !pip uninstall tensorflow\n",
        "!pip install tensorflow==2.7.0 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hrkmza94S0B",
        "outputId": "5da682d9-803d-48f6-9b2a-d1d12cfaf210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.7.0\n",
            "  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.7.0%2Bzzzcolab20220506150900-cp37-cp37m-linux_x86_64.whl (665.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 665.5 MB 22 kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.49.1)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (2.9.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.27.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (14.0.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.17.3)\n",
            "Collecting keras<2.8,>=2.7.0rc0\n",
            "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 32.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (4.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.12)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.14.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.6.3)\n",
            "Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
            "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
            "\u001b[K     |████████████████████████████████| 463 kB 73.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.21.6)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (2.0.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.15.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow==2.7.0) (1.5.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (5.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (3.9.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (3.2.1)\n",
            "Installing collected packages: tensorflow-estimator, keras, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "Successfully installed keras-2.7.0 tensorflow-2.7.0+zzzcolab20220506150900 tensorflow-estimator-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unt7iw1IyqrJ"
      },
      "outputs": [],
      "source": [
        "# import the necessary packages\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# construct the argument parse and parse the arguments\n",
        "\n",
        "# This is not necessary\n"
      ],
      "metadata": {
        "id": "IyKnLlUO6Eye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the training and testing data, then scale it into the\n",
        "# range [0, 1]\n"
      ],
      "metadata": {
        "id": "CkW_ayqW6HXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the labels from integers to vectors\n",
        "\n",
        "\n",
        "# initialize the label names for the CIFAR-10 dataset\n",
        "\n",
        "\n",
        "# initialize the optimizer and model\n"
      ],
      "metadata": {
        "id": "T-ns4rWo6KMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the network\n"
      ],
      "metadata": {
        "id": "vpSeUaL66Mgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the network\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ee6SqX5M6Owg",
        "outputId": "9ae3743c-66ac-4e41-b474-00d760e30f29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    airplane       0.87      0.82      0.84      1000\n",
            "  automobile       0.93      0.90      0.92      1000\n",
            "        bird       0.78      0.70      0.74      1000\n",
            "         cat       0.68      0.64      0.66      1000\n",
            "        deer       0.77      0.83      0.80      1000\n",
            "         dog       0.69      0.78      0.74      1000\n",
            "        frog       0.87      0.87      0.87      1000\n",
            "       horse       0.87      0.87      0.87      1000\n",
            "        ship       0.88      0.92      0.90      1000\n",
            "       truck       0.89      0.89      0.89      1000\n",
            "\n",
            "    accuracy                           0.82     10000\n",
            "   macro avg       0.82      0.82      0.82     10000\n",
            "weighted avg       0.82      0.82      0.82     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the training loss and accuracy\n",
        "\n",
        "\n",
        "plt.show()\n",
        "# plt.savefig(\"cifar10_minivggnet_with_bn.png\")\n"
      ],
      "metadata": {
        "id": "vSCQN-2u6P-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now repeat without Batch Normalization and discuss."
      ],
      "metadata": {
        "id": "VKNoObitDku9"
      }
    }
  ]
}